#!/usr/bin/env perl

=head1 NAME

wp-tools - tools to backup and upgrade WordPress installations

=head1 SYNOPSIS

    # simple installation from CPAN
    cpanm App::WordPressTools

    # view usage information
    wp-tools --help

    # common usage
    wp-tools upgrade|backup|restore OPTIONS...

=head1 DESCRIPTION

WordPress Tools is a set of tools that allow you to backup, restore, and upgrade WordPress sites. The tools are
especially useful for upgrading very outdated sites and for scripting the backing up and upgrading of B<many> sites.

WordPress Tools was built to make the Internet more secure. A huge number of websites on the Internet use
L<WordPress|https://wordpress.org/>, because it's awesome, but a large portion of those sites do not run the latest
version of WordPress which makes them susceptible to hacking. WordPress Tools can be used to get those sites up-to-date
again, and that makes the whole Internet more secure.

The code has been used in production and has already upgraded over two million WordPress sites, but it has little
real-world testing outside of Linux at this point so your mileage may vary if you have a different operating system.
Stay tuned as we add support for more platforms, and please contribute if you feel like it.

The command-line program also has a lot of options for managing server load, so you can upgrade your sites without
killing your server.

=head1 INSTALLATION

There are several ways to install WordPress Tools to your system.

Make sure you have L<WP-CLI|http://wp-cli.org/> and the other L</DEPENDENCIES> installed.

=head2 Using cpanm

You can install WordPress Tools using L<cpanm>. If you have a local perl (plenv, perlbrew, etc.), you can just do:

    cpanm App::WordPressTools

to install the F<wp-tools> executable and its dependencies. The executable will be installed to your perl's bin path,
like F<~/perl5/perlbrew/bin/wp-tools>.

If you're installing to your system perl, you can do:

    cpanm --sudo App::WordPressTools

to install the F<wp-tools> executable to a system directory, like F</usr/local/bin/wp-tools> (depending on your perl).

=head2 Downloading just the executable

You may also choose to download F<wp-tools> as a single executable, like this:

    curl -OL https://raw.githubusercontent.com/bluehost/wp-tools/solo/wp-tools
    chmod +x wp-tools

This executable includes all the non-core Perl module dependencies built-in.

=head2 For developers

If you're a developer and want to hack on the source, clone the repository and pull the dependencies:

    git clone https://github.com/bluehost/wp-tools.git
    cd wp-tools
    cpanm Dist::Zilla
    dzil authordeps --missing | cpanm
    dzil listdeps --author --develop --missing | cpanm

=head1 DEPENDENCIES

WordPress Tools requires these other programs and libraries in order to do its work. You probably have most of these on
your system already, and the cpanm method of installing wp-tools will handle the Perl module dependencies for you.

=over 4

=item *

L<WP-CLI|http://wp-cli.org/>

=item *

L<GNU Coreutils|https://www.gnu.org/software/coreutils/>

=item *

L<GNU Tar|https://www.gnu.org/software/tar/>

=item *

awk

=item *

grep

=item *

mysql (MySQL server client)

=item *

procps

=item *

Various Perl modules (see the distributed F<cpanfile> file for a list)

=back

=head1 OPTIONS

=over 4

=item --help

Show usage information and exit.

=item --force

If there are any resource limits in effect, ignore them and do the command anyway.

=item --max-count=num

Delete the oldest backups, keeping the number provided (default: 5).

=item --max-dproc=num

Refuse to execute if the maximum number of defunct processes on the system exceeds this number (default: 100).

=item --max-load=num

Refuse to execute if the load average exceeds this number (default: 200).

=item --max-size=num

Refuse to back up a site if its uncompressed size on disk exceeds this number of bytes (default: 5368709120).

=item --max-run=num

Do not allow more than this number of concurrent system-wide executions of the script (default: 50).

=item --min-freemem=num

Refuse to execute if free memory has dropped below this number of bytes (default: 1048576).

=item --wp-cli=path

If your F<wp-cli> program has a different name than F<wp> or is not in your C<$PATH>, you can specify the command to be
used to call wp-cli.

=item --username=name

If you run wp-tools as a root user, it will drop permissions to the specified user and C<chdir> to their home directory.

=back

=head1 COMMANDS

=over 4

=item upgrade

The upgrade command will upgrade your WordPress core, themes, and plugins to the latest version available. It takes
a full backup prior to the update. After the update, wp-tools will do a quick check to try to determine that nothing
broke on your site. If any failures are detected, wp-tools will automatically restore to the backup taken prior to
update.

=item backup

The backup command will create a full backup, including database, of your WordPress installation as long as it is under
the --max-size limit (pre-compression).

=item restore

The restore command will restore a WordPress installation from a backup taken using the backup command.

=back

=head1 EXAMPLES

    # upgrade a site
    wp-tools upgrade --path=public_html/myblog \
                     --backupdir=myblog_backups

    # upgrade only plugins and themes
    wp-tools upgrade --path=public_html/myblog  \
                     --backupdir=myblog_backups \
                     --components=plugin,theme

    # backup a site
    wp-tools backup --path=public_html/mysite \
                    --backupdir=backups/mysite

    # restore a site to a previous state
    wp-tools restore --backupfile=backups/mysite/wp_backup1428524082.tar.gz

=head1 BUGS

Currently, wp-tools tries very hard to run with your C<$HOME> as the current working directory. It will C<chdir> there
before executing its command, and it does B<NOT> translate relative paths. This means that if you run wp-tools from
outside of your home directory with a relative path, your paths won't be found. This is a temporary limitation that will
be fixed soon.

=head1 CONTRIBUTORS

Many people were involved in the creation of WordPress Tools. In particular:

=over 4

=item *

Matt Andersen

=item *

Gabriel Peery

=back

=head1 AUTHORS

=over 4

=item *

Seth Johnson <sj@bluehost.com>

=item *

Charles McGarvey <cmcgarvey@bluehost.com>

=item *

Garth Mortensen <gmortensen@bluehost.com>

=back

=head1 COPYRIGHT AND LICENSE

This software is copyright (c) 2016 by Bluehost Inc.

This is free software, licensed under:

The GNU General Public License, Version 2, June 1991

=cut


# This chunk of stuff was generated by App::FatPacker. To find the original
# file's code, look for the end of this BEGIN block or the string 'FATPACK'
BEGIN {
my %fatpacked;

$fatpacked{"App/WordPressTools.pm"} = '#line '.(1+__LINE__).' "'.__FILE__."\"\n".<<'APP_WORDPRESSTOOLS';
  package App::WordPressTools;our$VERSION='1.01';1;
APP_WORDPRESSTOOLS

$fatpacked{"File/Slurper.pm"} = '#line '.(1+__LINE__).' "'.__FILE__."\"\n".<<'FILE_SLURPER';
  package File::Slurper;$File::Slurper::VERSION='0.008';use strict;use warnings;use Carp 'croak';use Exporter 5.57 'import';our@EXPORT_OK=qw/read_binary read_text read_lines write_binary write_text read_dir/;sub read_binary {my$filename=shift;open my$fh,'<:unix',$filename or croak "Couldn't open $filename: $!";if (my$size=-s $fh){my$buf;my ($pos,$read)=0;do {defined($read=read$fh,${$buf},$size - $pos,$pos)or croak "Couldn't read $filename: $!";$pos += $read}while ($read && $pos < $size);return ${$buf}}else {return do {local $/;<$fh>}}}use constant {CRLF_DEFAULT=>$^O eq 'MSWin32',HAS_UTF8_STRICT=>scalar do {local $@;eval {require PerlIO::utf8_strict}},};sub _text_layers {my ($encoding,$crlf)=@_;$crlf=CRLF_DEFAULT if$crlf && $crlf eq 'auto';if ($encoding =~ /^(latin|iso-8859-)1$/i){return$crlf ? ':unix:crlf' : ':raw'}elsif (HAS_UTF8_STRICT && $encoding =~ /^utf-?8\b/i){return$crlf ? ':unix:utf8_strict:crlf' : ':unix:utf8_strict'}else {return$crlf ? ":raw:encoding($encoding):crlf" : ":raw:encoding($encoding)"}}sub read_text {my ($filename,$encoding,$crlf)=@_;$encoding ||= 'utf-8';my$layer=_text_layers($encoding,$crlf);return read_binary($filename)if$layer eq ':raw';local$PerlIO::encoding::fallback=1;open my$fh,"<$layer",$filename or croak "Couldn't open $filename: $!";return do {local $/;<$fh>}}sub write_text {my ($filename,undef,$encoding,$crlf)=@_;$encoding ||= 'utf-8';my$layer=_text_layers($encoding,$crlf);local$PerlIO::encoding::fallback=1;open my$fh,">$layer",$filename or croak "Couldn't open $filename: $!";print$fh $_[1]or croak "Couldn't write to $filename: $!";close$fh or croak "Couldn't write to $filename: $!";return}sub write_binary {return write_text(@_[0,1],'latin-1')}sub read_lines {my ($filename,$encoding,$crlf,$skip_chomp)=@_;$encoding ||= 'utf-8';my$layer=_text_layers($encoding,$crlf);local$PerlIO::encoding::fallback=1;open my$fh,"<$layer",$filename or croak "Couldn't open $filename: $!";return <$fh> if$skip_chomp;my@buf=<$fh>;close$fh;chomp@buf;return@buf}sub read_dir {my ($dirname)=@_;opendir my ($dir),$dirname or croak "Could not open $dirname: $!";return grep {not m/ \A \.\.? \z /x}readdir$dir}1;
FILE_SLURPER

$fatpacked{"HTTP/Tiny.pm"} = '#line '.(1+__LINE__).' "'.__FILE__."\"\n".<<'HTTP_TINY';
  package HTTP::Tiny;use strict;use warnings;our$VERSION='0.056';use Carp ();my@attributes;BEGIN {@attributes=qw(cookie_jar default_headers http_proxy https_proxy keep_alive local_address max_redirect max_size proxy no_proxy timeout SSL_options verify_SSL);my%persist_ok=map {;$_=>1}qw(cookie_jar default_headers max_redirect max_size);no strict 'refs';no warnings 'uninitialized';for my$accessor (@attributes){*{$accessor}=sub {@_ > 1 ? do {delete $_[0]->{handle}if!$persist_ok{$accessor}&& $_[1]ne $_[0]->{$accessor};$_[0]->{$accessor}=$_[1]}: $_[0]->{$accessor}}}}sub agent {my($self,$agent)=@_;if(@_ > 1){$self->{agent}=(defined$agent && $agent =~ / $/)? $agent .$self->_agent : $agent}return$self->{agent}}sub new {my($class,%args)=@_;my$self={max_redirect=>5,timeout=>60,keep_alive=>1,verify_SSL=>$args{verify_SSL}|| $args{verify_ssl}|| 0,no_proxy=>$ENV{no_proxy},};bless$self,$class;$class->_validate_cookie_jar($args{cookie_jar})if$args{cookie_jar};for my$key (@attributes){$self->{$key}=$args{$key}if exists$args{$key}}$self->agent(exists$args{agent}? $args{agent}: $class->_agent);$self->_set_proxies;return$self}sub _set_proxies {my ($self)=@_;if (!exists$self->{proxy}){$self->{proxy}=$ENV{all_proxy}|| $ENV{ALL_PROXY}}if (defined$self->{proxy}){$self->_split_proxy('generic proxy'=>$self->{proxy})}else {delete$self->{proxy}}if (!exists$self->{http_proxy}){local$ENV{HTTP_PROXY}if$ENV{REQUEST_METHOD};$self->{http_proxy}=$ENV{http_proxy}|| $ENV{HTTP_PROXY}|| $self->{proxy}}if (defined$self->{http_proxy}){$self->_split_proxy(http_proxy=>$self->{http_proxy});$self->{_has_proxy}{http}=1}else {delete$self->{http_proxy}}if (!exists$self->{https_proxy}){$self->{https_proxy}=$ENV{https_proxy}|| $ENV{HTTPS_PROXY}|| $self->{proxy}}if ($self->{https_proxy}){$self->_split_proxy(https_proxy=>$self->{https_proxy});$self->{_has_proxy}{https}=1}else {delete$self->{https_proxy}}unless (ref$self->{no_proxy}eq 'ARRAY'){$self->{no_proxy}=(defined$self->{no_proxy})? [split /\s*,\s*/,$self->{no_proxy}]: []}return}for my$sub_name (qw/get head put post delete/){my$req_method=uc$sub_name;no strict 'refs';eval <<"HERE"}sub post_form {my ($self,$url,$data,$args)=@_;(@_==3 || @_==4 && ref$args eq 'HASH')or Carp::croak(q/Usage: $http->post_form(URL, DATAREF, [HASHREF])/ ."\n");my$headers={};while (my ($key,$value)=each %{$args->{headers}|| {}}){$headers->{lc$key}=$value}delete$args->{headers};return$self->request('POST',$url,{%$args,content=>$self->www_form_urlencode($data),headers=>{%$headers,'content-type'=>'application/x-www-form-urlencoded' },})}sub mirror {my ($self,$url,$file,$args)=@_;@_==3 || (@_==4 && ref$args eq 'HASH')or Carp::croak(q/Usage: $http->mirror(URL, FILE, [HASHREF])/ ."\n");if (-e $file and my$mtime=(stat($file))[9]){$args->{headers}{'if-modified-since'}||= $self->_http_date($mtime)}my$tempfile=$file .int(rand(2**31));require Fcntl;sysopen my$fh,$tempfile,Fcntl::O_CREAT()|Fcntl::O_EXCL()|Fcntl::O_WRONLY()or Carp::croak(qq/Error: Could not create temporary file $tempfile for downloading: $!\n/);binmode$fh;$args->{data_callback}=sub {print {$fh}$_[0]};my$response=$self->request('GET',$url,$args);close$fh or Carp::croak(qq/Error: Caught error closing temporary file $tempfile: $!\n/);if ($response->{success}){rename$tempfile,$file or Carp::croak(qq/Error replacing $file with $tempfile: $!\n/);my$lm=$response->{headers}{'last-modified'};if ($lm and my$mtime=$self->_parse_http_date($lm)){utime$mtime,$mtime,$file}}$response->{success}||= $response->{status}eq '304';unlink$tempfile;return$response}my%idempotent=map {$_=>1}qw/GET HEAD PUT DELETE OPTIONS TRACE/;sub request {my ($self,$method,$url,$args)=@_;@_==3 || (@_==4 && ref$args eq 'HASH')or Carp::croak(q/Usage: $http->request(METHOD, URL, [HASHREF])/ ."\n");$args ||= {};my$response;for (0 .. 1){$response=eval {$self->_request($method,$url,$args)};last unless $@ && $idempotent{$method}&& $@ =~ m{^(?:Socket closed|Unexpected end)}}if (my$e=$@){if (ref$e eq 'HASH' && exists$e->{status}){return$e}$e="$e";$response={url=>$url,success=>q{},status=>599,reason=>'Internal Exception',content=>$e,headers=>{'content-type'=>'text/plain','content-length'=>length$e,}}}return$response}sub www_form_urlencode {my ($self,$data)=@_;(@_==2 && ref$data)or Carp::croak(q/Usage: $http->www_form_urlencode(DATAREF)/ ."\n");(ref$data eq 'HASH' || ref$data eq 'ARRAY')or Carp::croak("form data must be a hash or array reference\n");my@params=ref$data eq 'HASH' ? %$data : @$data;@params % 2==0 or Carp::croak("form data reference must have an even number of terms\n");my@terms;while(@params){my ($key,$value)=splice(@params,0,2);if (ref$value eq 'ARRAY'){unshift@params,map {$key=>$_}@$value}else {push@terms,join("=",map {$self->_uri_escape($_)}$key,$value)}}return join("&",(ref$data eq 'ARRAY')? (@terms): (sort@terms))}sub can_ssl {my ($self)=@_;my($ok,$reason)=(1,'');unless (eval {require IO::Socket::SSL;IO::Socket::SSL->VERSION(1.42)}){$ok=0;$reason .= qq/IO::Socket::SSL 1.42 must be installed for https support\n/}unless (eval {require Net::SSLeay;Net::SSLeay->VERSION(1.49)}){$ok=0;$reason .= qq/Net::SSLeay 1.49 must be installed for https support\n/}if (ref($self)&& ($self->{verify_SSL}|| $self->{SSL_options}{SSL_verify_mode})){my$handle=HTTP::Tiny::Handle->new(SSL_options=>$self->{SSL_options},verify_SSL=>$self->{verify_SSL},);unless (eval {$handle->_find_CA_file;1}){$ok=0;$reason .= "$@"}}wantarray ? ($ok,$reason): $ok}my%DefaultPort=(http=>80,https=>443,);sub _agent {my$class=ref($_[0])|| $_[0];(my$default_agent=$class)=~ s{::}{-}g;return$default_agent ."/" .$class->VERSION}sub _request {my ($self,$method,$url,$args)=@_;my ($scheme,$host,$port,$path_query,$auth)=$self->_split_url($url);my$request={method=>$method,scheme=>$scheme,host=>$host,port=>$port,host_port=>($port==$DefaultPort{$scheme}? $host : "$host:$port"),uri=>$path_query,headers=>{},};my$handle=delete$self->{handle};if ($handle){unless ($handle->can_reuse($scheme,$host,$port)){$handle->close;undef$handle}}$handle ||= $self->_open_handle($request,$scheme,$host,$port);$self->_prepare_headers_and_cb($request,$args,$url,$auth);$handle->write_request($request);my$response;do {$response=$handle->read_response_header}until (substr($response->{status},0,1)ne '1');$self->_update_cookie_jar($url,$response)if$self->{cookie_jar};if (my@redir_args=$self->_maybe_redirect($request,$response,$args)){$handle->close;return$self->_request(@redir_args,$args)}my$known_message_length;if ($method eq 'HEAD' || $response->{status}=~ /^[23]04/){$known_message_length=1}else {my$data_cb=$self->_prepare_data_cb($response,$args);$known_message_length=$handle->read_body($data_cb,$response)}if ($self->{keep_alive}&& $known_message_length && $response->{protocol}eq 'HTTP/1.1' && ($response->{headers}{connection}|| '')ne 'close'){$self->{handle}=$handle}else {$handle->close}$response->{success}=substr($response->{status},0,1)eq '2';$response->{url}=$url;return$response}sub _open_handle {my ($self,$request,$scheme,$host,$port)=@_;my$handle=HTTP::Tiny::Handle->new(timeout=>$self->{timeout},SSL_options=>$self->{SSL_options},verify_SSL=>$self->{verify_SSL},local_address=>$self->{local_address},keep_alive=>$self->{keep_alive});if ($self->{_has_proxy}{$scheme}&&!grep {$host =~ /\Q$_\E$/}@{$self->{no_proxy}}){return$self->_proxy_connect($request,$handle)}else {return$handle->connect($scheme,$host,$port)}}sub _proxy_connect {my ($self,$request,$handle)=@_;my@proxy_vars;if ($request->{scheme}eq 'https'){Carp::croak(qq{No https_proxy defined})unless$self->{https_proxy};@proxy_vars=$self->_split_proxy(https_proxy=>$self->{https_proxy});if ($proxy_vars[0]eq 'https'){Carp::croak(qq{Can't proxy https over https: $request->{uri} via $self->{https_proxy}})}}else {Carp::croak(qq{No http_proxy defined})unless$self->{http_proxy};@proxy_vars=$self->_split_proxy(http_proxy=>$self->{http_proxy})}my ($p_scheme,$p_host,$p_port,$p_auth)=@proxy_vars;if (length$p_auth &&!defined$request->{headers}{'proxy-authorization'}){$self->_add_basic_auth_header($request,'proxy-authorization'=>$p_auth)}$handle->connect($p_scheme,$p_host,$p_port);if ($request->{scheme}eq 'https'){$self->_create_proxy_tunnel($request,$handle)}else {$request->{uri}="$request->{scheme}://$request->{host_port}$request->{uri}"}return$handle}sub _split_proxy {my ($self,$type,$proxy)=@_;my ($scheme,$host,$port,$path_query,$auth)=eval {$self->_split_url($proxy)};unless(defined($scheme)&& length($scheme)&& length($host)&& length($port)&& $path_query eq '/'){Carp::croak(qq{$type URL must be in format http[s]://[auth@]<host>:<port>/\n})}return ($scheme,$host,$port,$auth)}sub _create_proxy_tunnel {my ($self,$request,$handle)=@_;$handle->_assert_ssl;my$agent=exists($request->{headers}{'user-agent'})? $request->{headers}{'user-agent'}: $self->{agent};my$connect_request={method=>'CONNECT',uri=>"$request->{host}:$request->{port}",headers=>{host=>"$request->{host}:$request->{port}",'user-agent'=>$agent,}};if ($request->{headers}{'proxy-authorization'}){$connect_request->{headers}{'proxy-authorization'}=delete$request->{headers}{'proxy-authorization'}}$handle->write_request($connect_request);my$response;do {$response=$handle->read_response_header}until (substr($response->{status},0,1)ne '1');unless (substr($response->{status},0,1)eq '2'){die$response}$handle->start_ssl($request->{host});return}sub _prepare_headers_and_cb {my ($self,$request,$args,$url,$auth)=@_;for ($self->{default_headers},$args->{headers}){next unless defined;while (my ($k,$v)=each %$_){$request->{headers}{lc$k}=$v}}if (exists$request->{headers}{'host'}){die(qq/The 'Host' header must not be provided as header option\n/)}$request->{headers}{'host'}=$request->{host_port};$request->{headers}{'user-agent'}||= $self->{agent};$request->{headers}{'connection'}="close" unless$self->{keep_alive};if (defined$args->{content}){if (ref$args->{content}eq 'CODE'){$request->{headers}{'content-type'}||= "application/octet-stream";$request->{headers}{'transfer-encoding'}='chunked' unless$request->{headers}{'content-length'}|| $request->{headers}{'transfer-encoding'};$request->{cb}=$args->{content}}elsif (length$args->{content}){my$content=$args->{content};if ($] ge '5.008'){utf8::downgrade($content,1)or die(qq/Wide character in request message body\n/)}$request->{headers}{'content-type'}||= "application/octet-stream";$request->{headers}{'content-length'}=length$content unless$request->{headers}{'content-length'}|| $request->{headers}{'transfer-encoding'};$request->{cb}=sub {substr$content,0,length$content,''}}$request->{trailer_cb}=$args->{trailer_callback}if ref$args->{trailer_callback}eq 'CODE'}if ($self->{cookie_jar}){my$cookies=$self->cookie_jar->cookie_header($url);$request->{headers}{cookie}=$cookies if length$cookies}if (length$auth &&!defined$request->{headers}{authorization}){$self->_add_basic_auth_header($request,'authorization'=>$auth)}return}sub _add_basic_auth_header {my ($self,$request,$header,$auth)=@_;require MIME::Base64;$request->{headers}{$header}="Basic " .MIME::Base64::encode_base64($auth,"");return}sub _prepare_data_cb {my ($self,$response,$args)=@_;my$data_cb=$args->{data_callback};$response->{content}='';if (!$data_cb || $response->{status}!~ /^2/){if (defined$self->{max_size}){$data_cb=sub {$_[1]->{content}.= $_[0];die(qq/Size of response body exceeds the maximum allowed of $self->{max_size}\n/)if length $_[1]->{content}> $self->{max_size}}}else {$data_cb=sub {$_[1]->{content}.= $_[0]}}}return$data_cb}sub _update_cookie_jar {my ($self,$url,$response)=@_;my$cookies=$response->{headers}->{'set-cookie'};return unless defined$cookies;my@cookies=ref$cookies ? @$cookies : $cookies;$self->cookie_jar->add($url,$_)for@cookies;return}sub _validate_cookie_jar {my ($class,$jar)=@_;for my$method (qw/add cookie_header/){Carp::croak(qq/Cookie jar must provide the '$method' method\n/)unless ref($jar)&& ref($jar)->can($method)}return}sub _maybe_redirect {my ($self,$request,$response,$args)=@_;my$headers=$response->{headers};my ($status,$method)=($response->{status},$request->{method});if (($status eq '303' or ($status =~ /^30[1278]/ && $method =~ /^GET|HEAD$/))and $headers->{location}and ++$args->{redirects}<= $self->{max_redirect}){my$location=($headers->{location}=~ /^\//)? "$request->{scheme}://$request->{host_port}$headers->{location}" : $headers->{location};return (($status eq '303' ? 'GET' : $method),$location)}return}sub _split_url {my$url=pop;my ($scheme,$host,$path_query)=$url =~ m<\A([^:/?#]+)://([^/?#]*)([^#]*)> or die(qq/Cannot parse URL: '$url'\n/);$scheme=lc$scheme;$path_query="/$path_query" unless$path_query =~ m<\A/>;my$auth='';if ((my$i=index$host,'@')!=-1){$auth=substr$host,0,$i,'';substr$host,0,1,'';$auth =~ s/%([0-9A-Fa-f]{2})/chr(hex($1))/eg}my$port=$host =~ s/:(\d*)\z// && length $1 ? $1 : $scheme eq 'http' ? 80 : $scheme eq 'https' ? 443 : undef;return ($scheme,(length$host ? lc$host : "localhost"),$port,$path_query,$auth)}my$DoW="Sun|Mon|Tue|Wed|Thu|Fri|Sat";my$MoY="Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec";sub _http_date {my ($sec,$min,$hour,$mday,$mon,$year,$wday)=gmtime($_[1]);return sprintf("%s, %02d %s %04d %02d:%02d:%02d GMT",substr($DoW,$wday*4,3),$mday,substr($MoY,$mon*4,3),$year+1900,$hour,$min,$sec)}sub _parse_http_date {my ($self,$str)=@_;require Time::Local;my@tl_parts;if ($str =~ /^[SMTWF][a-z]+, +(\d{1,2}) ($MoY) +(\d\d\d\d) +(\d\d):(\d\d):(\d\d) +GMT$/){@tl_parts=($6,$5,$4,$1,(index($MoY,$2)/4),$3)}elsif ($str =~ /^[SMTWF][a-z]+, +(\d\d)-($MoY)-(\d{2,4}) +(\d\d):(\d\d):(\d\d) +GMT$/){@tl_parts=($6,$5,$4,$1,(index($MoY,$2)/4),$3)}elsif ($str =~ /^[SMTWF][a-z]+ +($MoY) +(\d{1,2}) +(\d\d):(\d\d):(\d\d) +(?:[^0-9]+ +)?(\d\d\d\d)$/){@tl_parts=($5,$4,$3,$2,(index($MoY,$1)/4),$6)}return eval {my$t=@tl_parts ? Time::Local::timegm(@tl_parts): -1;$t < 0 ? undef : $t}}my%escapes=map {chr($_)=>sprintf("%%%02X",$_)}0..255;$escapes{' '}="+";my$unsafe_char=qr/[^A-Za-z0-9\-\._~]/;sub _uri_escape {my ($self,$str)=@_;if ($] ge '5.008'){utf8::encode($str)}else {$str=pack("U*",unpack("C*",$str))if (length$str==do {use bytes;length$str});$str=pack("C*",unpack("C*",$str))}$str =~ s/($unsafe_char)/$escapes{$1}/ge;return$str}package HTTP::Tiny::Handle;use strict;use warnings;use Errno qw[EINTR EPIPE];use IO::Socket qw[SOCK_STREAM];my$SOCKET_CLASS=$ENV{PERL_HTTP_TINY_IPV4_ONLY}? 'IO::Socket::INET' : eval {require IO::Socket::IP;IO::Socket::IP->VERSION(0.25)}? 'IO::Socket::IP' : 'IO::Socket::INET';sub BUFSIZE () {32768}my$Printable=sub {local $_=shift;s/\r/\\r/g;s/\n/\\n/g;s/\t/\\t/g;s/([^\x20-\x7E])/sprintf('\\x%.2X', ord($1))/ge;$_};my$Token=qr/[\x21\x23-\x27\x2A\x2B\x2D\x2E\x30-\x39\x41-\x5A\x5E-\x7A\x7C\x7E]/;sub new {my ($class,%args)=@_;return bless {rbuf=>'',timeout=>60,max_line_size=>16384,max_header_lines=>64,verify_SSL=>0,SSL_options=>{},%args },$class}sub connect {@_==4 || die(q/Usage: $handle->connect(scheme, host, port)/ ."\n");my ($self,$scheme,$host,$port)=@_;if ($scheme eq 'https'){$self->_assert_ssl}elsif ($scheme ne 'http'){die(qq/Unsupported URL scheme '$scheme'\n/)}$self->{fh}=$SOCKET_CLASS->new(PeerHost=>$host,PeerPort=>$port,$self->{local_address}? (LocalAddr=>$self->{local_address}): (),Proto=>'tcp',Type=>SOCK_STREAM,Timeout=>$self->{timeout},KeepAlive=>!!$self->{keep_alive})or die(qq/Could not connect to '$host:$port': $@\n/);binmode($self->{fh})or die(qq/Could not binmode() socket: '$!'\n/);$self->start_ssl($host)if$scheme eq 'https';$self->{scheme}=$scheme;$self->{host}=$host;$self->{port}=$port;$self->{pid}=$$;$self->{tid}=_get_tid();return$self}sub start_ssl {my ($self,$host)=@_;if (ref($self->{fh})eq 'IO::Socket::SSL'){unless ($self->{fh}->stop_SSL){my$ssl_err=IO::Socket::SSL->errstr;die(qq/Error halting prior SSL connection: $ssl_err/)}}my$ssl_args=$self->_ssl_args($host);IO::Socket::SSL->start_SSL($self->{fh},%$ssl_args,SSL_create_ctx_callback=>sub {my$ctx=shift;Net::SSLeay::CTX_set_mode($ctx,Net::SSLeay::MODE_AUTO_RETRY())},);unless (ref($self->{fh})eq 'IO::Socket::SSL'){my$ssl_err=IO::Socket::SSL->errstr;die(qq/SSL connection failed for $host: $ssl_err\n/)}}sub close {@_==1 || die(q/Usage: $handle->close()/ ."\n");my ($self)=@_;CORE::close($self->{fh})or die(qq/Could not close socket: '$!'\n/)}sub write {@_==2 || die(q/Usage: $handle->write(buf)/ ."\n");my ($self,$buf)=@_;if ($] ge '5.008'){utf8::downgrade($buf,1)or die(qq/Wide character in write()\n/)}my$len=length$buf;my$off=0;local$SIG{PIPE}='IGNORE';while (){$self->can_write or die(qq/Timed out while waiting for socket to become ready for writing\n/);my$r=syswrite($self->{fh},$buf,$len,$off);if (defined$r){$len -= $r;$off += $r;last unless$len > 0}elsif ($!==EPIPE){die(qq/Socket closed by remote server: $!\n/)}elsif ($!!=EINTR){if ($self->{fh}->can('errstr')){my$err=$self->{fh}->errstr();die (qq/Could not write to SSL socket: '$err'\n /)}else {die(qq/Could not write to socket: '$!'\n/)}}}return$off}sub read {@_==2 || @_==3 || die(q/Usage: $handle->read(len [, allow_partial])/ ."\n");my ($self,$len,$allow_partial)=@_;my$buf='';my$got=length$self->{rbuf};if ($got){my$take=($got < $len)? $got : $len;$buf=substr($self->{rbuf},0,$take,'');$len -= $take}while ($len > 0){$self->can_read or die(q/Timed out while waiting for socket to become ready for reading/ ."\n");my$r=sysread($self->{fh},$buf,$len,length$buf);if (defined$r){last unless$r;$len -= $r}elsif ($!!=EINTR){if ($self->{fh}->can('errstr')){my$err=$self->{fh}->errstr();die (qq/Could not read from SSL socket: '$err'\n /)}else {die(qq/Could not read from socket: '$!'\n/)}}}if ($len &&!$allow_partial){die(qq/Unexpected end of stream\n/)}return$buf}sub readline {@_==1 || die(q/Usage: $handle->readline()/ ."\n");my ($self)=@_;while (){if ($self->{rbuf}=~ s/\A ([^\x0D\x0A]* \x0D?\x0A)//x){return $1}if (length$self->{rbuf}>= $self->{max_line_size}){die(qq/Line size exceeds the maximum allowed size of $self->{max_line_size}\n/)}$self->can_read or die(qq/Timed out while waiting for socket to become ready for reading\n/);my$r=sysread($self->{fh},$self->{rbuf},BUFSIZE,length$self->{rbuf});if (defined$r){last unless$r}elsif ($!!=EINTR){if ($self->{fh}->can('errstr')){my$err=$self->{fh}->errstr();die (qq/Could not read from SSL socket: '$err'\n /)}else {die(qq/Could not read from socket: '$!'\n/)}}}die(qq/Unexpected end of stream while looking for line\n/)}sub read_header_lines {@_==1 || @_==2 || die(q/Usage: $handle->read_header_lines([headers])/ ."\n");my ($self,$headers)=@_;$headers ||= {};my$lines=0;my$val;while (){my$line=$self->readline;if (++$lines >= $self->{max_header_lines}){die(qq/Header lines exceeds maximum number allowed of $self->{max_header_lines}\n/)}elsif ($line =~ /\A ([^\x00-\x1F\x7F:]+) : [\x09\x20]* ([^\x0D\x0A]*)/x){my ($field_name)=lc $1;if (exists$headers->{$field_name}){for ($headers->{$field_name}){$_=[$_]unless ref $_ eq "ARRAY";push @$_,$2;$val=\$_->[-1]}}else {$val=\($headers->{$field_name}=$2)}}elsif ($line =~ /\A [\x09\x20]+ ([^\x0D\x0A]*)/x){$val or die(qq/Unexpected header continuation line\n/);next unless length $1;$$val .= ' ' if length $$val;$$val .= $1}elsif ($line =~ /\A \x0D?\x0A \z/x){last}else {die(q/Malformed header line: / .$Printable->($line)."\n")}}return$headers}sub write_request {@_==2 || die(q/Usage: $handle->write_request(request)/ ."\n");my($self,$request)=@_;$self->write_request_header(@{$request}{qw/method uri headers/});$self->write_body($request)if$request->{cb};return}my%HeaderCase=('content-md5'=>'Content-MD5','etag'=>'ETag','te'=>'TE','www-authenticate'=>'WWW-Authenticate','x-xss-protection'=>'X-XSS-Protection',);sub write_header_lines {(@_==2 || @_==3 && ref $_[1]eq 'HASH')|| die(q/Usage: $handle->write_header_lines(headers[,prefix])/ ."\n");my($self,$headers,$prefix_data)=@_;my$buf=(defined$prefix_data ? $prefix_data : '');while (my ($k,$v)=each %$headers){my$field_name=lc$k;if (exists$HeaderCase{$field_name}){$field_name=$HeaderCase{$field_name}}else {$field_name =~ /\A $Token+ \z/xo or die(q/Invalid HTTP header field name: / .$Printable->($field_name)."\n");$field_name =~ s/\b(\w)/\u$1/g;$HeaderCase{lc$field_name}=$field_name}for (ref$v eq 'ARRAY' ? @$v : $v){$_='' unless defined $_;$buf .= "$field_name: $_\x0D\x0A"}}$buf .= "\x0D\x0A";return$self->write($buf)}sub read_body {@_==3 || die(q/Usage: $handle->read_body(callback, response)/ ."\n");my ($self,$cb,$response)=@_;my$te=$response->{headers}{'transfer-encoding'}|| '';my$chunked=grep {/chunked/i}(ref$te eq 'ARRAY' ? @$te : $te);return$chunked ? $self->read_chunked_body($cb,$response): $self->read_content_body($cb,$response)}sub write_body {@_==2 || die(q/Usage: $handle->write_body(request)/ ."\n");my ($self,$request)=@_;if ($request->{headers}{'content-length'}){return$self->write_content_body($request)}else {return$self->write_chunked_body($request)}}sub read_content_body {@_==3 || @_==4 || die(q/Usage: $handle->read_content_body(callback, response, [read_length])/ ."\n");my ($self,$cb,$response,$content_length)=@_;$content_length ||= $response->{headers}{'content-length'};if (defined$content_length){my$len=$content_length;while ($len > 0){my$read=($len > BUFSIZE)? BUFSIZE : $len;$cb->($self->read($read,0),$response);$len -= $read}return length($self->{rbuf})==0}my$chunk;$cb->($chunk,$response)while length($chunk=$self->read(BUFSIZE,1));return}sub write_content_body {@_==2 || die(q/Usage: $handle->write_content_body(request)/ ."\n");my ($self,$request)=@_;my ($len,$content_length)=(0,$request->{headers}{'content-length'});while (){my$data=$request->{cb}->();defined$data && length$data or last;if ($] ge '5.008'){utf8::downgrade($data,1)or die(qq/Wide character in write_content()\n/)}$len += $self->write($data)}$len==$content_length or die(qq/Content-Length mismatch (got: $len expected: $content_length)\n/);return$len}sub read_chunked_body {@_==3 || die(q/Usage: $handle->read_chunked_body(callback, $response)/ ."\n");my ($self,$cb,$response)=@_;while (){my$head=$self->readline;$head =~ /\A ([A-Fa-f0-9]+)/x or die(q/Malformed chunk head: / .$Printable->($head)."\n");my$len=hex($1)or last;$self->read_content_body($cb,$response,$len);$self->read(2)eq "\x0D\x0A" or die(qq/Malformed chunk: missing CRLF after chunk data\n/)}$self->read_header_lines($response->{headers});return 1}sub write_chunked_body {@_==2 || die(q/Usage: $handle->write_chunked_body(request)/ ."\n");my ($self,$request)=@_;my$len=0;while (){my$data=$request->{cb}->();defined$data && length$data or last;if ($] ge '5.008'){utf8::downgrade($data,1)or die(qq/Wide character in write_chunked_body()\n/)}$len += length$data;my$chunk=sprintf '%X',length$data;$chunk .= "\x0D\x0A";$chunk .= $data;$chunk .= "\x0D\x0A";$self->write($chunk)}$self->write("0\x0D\x0A");$self->write_header_lines($request->{trailer_cb}->())if ref$request->{trailer_cb}eq 'CODE';return$len}sub read_response_header {@_==1 || die(q/Usage: $handle->read_response_header()/ ."\n");my ($self)=@_;my$line=$self->readline;$line =~ /\A (HTTP\/(0*\d+\.0*\d+)) [\x09\x20]+ ([0-9]{3}) [\x09\x20]+ ([^\x0D\x0A]*) \x0D?\x0A/x or die(q/Malformed Status-Line: / .$Printable->($line)."\n");my ($protocol,$version,$status,$reason)=($1,$2,$3,$4);die (qq/Unsupported HTTP protocol: $protocol\n/)unless$version =~ /0*1\.0*[01]/;return {status=>$status,reason=>$reason,headers=>$self->read_header_lines,protocol=>$protocol,}}sub write_request_header {@_==4 || die(q/Usage: $handle->write_request_header(method, request_uri, headers)/ ."\n");my ($self,$method,$request_uri,$headers)=@_;return$self->write_header_lines($headers,"$method $request_uri HTTP/1.1\x0D\x0A")}sub _do_timeout {my ($self,$type,$timeout)=@_;$timeout=$self->{timeout}unless defined$timeout && $timeout >= 0;my$fd=fileno$self->{fh};defined$fd && $fd >= 0 or die(qq/select(2): 'Bad file descriptor'\n/);my$initial=time;my$pending=$timeout;my$nfound;vec(my$fdset='',$fd,1)=1;while (){$nfound=($type eq 'read')? select($fdset,undef,undef,$pending): select(undef,$fdset,undef,$pending);if ($nfound==-1){$!==EINTR or die(qq/select(2): '$!'\n/);redo if!$timeout || ($pending=$timeout - (time - $initial))> 0;$nfound=0}last}$!=0;return$nfound}sub can_read {@_==1 || @_==2 || die(q/Usage: $handle->can_read([timeout])/ ."\n");my$self=shift;if (ref($self->{fh})eq 'IO::Socket::SSL'){return 1 if$self->{fh}->pending}return$self->_do_timeout('read',@_)}sub can_write {@_==1 || @_==2 || die(q/Usage: $handle->can_write([timeout])/ ."\n");my$self=shift;return$self->_do_timeout('write',@_)}sub _assert_ssl {my($ok,$reason)=HTTP::Tiny->can_ssl();die$reason unless$ok}sub can_reuse {my ($self,$scheme,$host,$port)=@_;return 0 if $self->{pid}!=$$ || $self->{tid}!=_get_tid()|| length($self->{rbuf})|| $scheme ne $self->{scheme}|| $host ne $self->{host}|| $port ne $self->{port}|| eval {$self->can_read(0)}|| $@ ;return 1}sub _find_CA_file {my$self=shift();if ($self->{SSL_options}->{SSL_ca_file}){unless (-r $self->{SSL_options}->{SSL_ca_file}){die qq/SSL_ca_file '$self->{SSL_options}->{SSL_ca_file}' not found or not readable\n/}return$self->{SSL_options}->{SSL_ca_file}}return Mozilla::CA::SSL_ca_file()if eval {require Mozilla::CA;1};for my$ca_bundle ("/etc/ssl/certs/ca-certificates.crt","/etc/pki/tls/certs/ca-bundle.crt","/etc/ssl/ca-bundle.pem","/etc/openssl/certs/ca-certificates.crt","/etc/ssl/cert.pem","/usr/local/share/certs/ca-root-nss.crt","/etc/pki/tls/cacert.pem","/etc/certs/ca-certificates.crt",){return$ca_bundle if -e $ca_bundle}die qq/Couldn't find a CA bundle with which to verify the SSL certificate.\n/ .qq/Try installing Mozilla::CA from CPAN\n/}sub _get_tid {no warnings 'reserved';return threads->can("tid")? threads->tid : 0}sub _ssl_args {my ($self,$host)=@_;my%ssl_args;if (Net::SSLeay::OPENSSL_VERSION_NUMBER()>= 0x01000000){$ssl_args{SSL_hostname}=$host,}if ($self->{verify_SSL}){$ssl_args{SSL_verifycn_scheme}='http';$ssl_args{SSL_verifycn_name}=$host;$ssl_args{SSL_verify_mode}=0x01;$ssl_args{SSL_ca_file}=$self->_find_CA_file}else {$ssl_args{SSL_verifycn_scheme}='none';$ssl_args{SSL_verify_mode}=0x00}for my$k (keys %{$self->{SSL_options}}){$ssl_args{$k}=$self->{SSL_options}{$k}if$k =~ m/^SSL_/}return \%ssl_args}1;
      sub $sub_name {
          my (\$self, \$url, \$args) = \@_;
          \@_ == 2 || (\@_ == 3 && ref \$args eq 'HASH')
          or Carp::croak(q/Usage: \$http->$sub_name(URL, [HASHREF])/ . "\n");
          return \$self->request('$req_method', \$url, \$args || {});
      }
  HERE
HTTP_TINY

$fatpacked{"String/ShellQuote.pm"} = '#line '.(1+__LINE__).' "'.__FILE__."\"\n".<<'STRING_SHELLQUOTE';
  package String::ShellQuote;use strict;use vars qw($VERSION @ISA @EXPORT);require Exporter;$VERSION='1.04';@ISA=qw(Exporter);@EXPORT=qw(shell_quote shell_quote_best_effort shell_comment_quote);sub croak {require Carp;goto&Carp::croak}sub _shell_quote_backend {my@in=@_;my@err=();if (0){require RS::Handy;print RS::Handy::data_dump(\@in)}return \@err,'' unless@in;my$ret='';my$saw_non_equal=0;for (@in){if (!defined $_ or $_ eq ''){$_="''";next}if (s/\x00//g){push@err,"No way to quote string containing null (\\000) bytes"}my$escape=0;if (/=/){if (!$saw_non_equal){$escape=1}}else {$saw_non_equal=1}if (m|[^\w!%+,\-./:=@^]|){$escape=1}if ($escape || (!$saw_non_equal && /=/)){s/'/'\\''/g;s|((?:'\\''){2,})|q{'"} . (q{'} x (length($1) / 4)) . q{"'}|ge;$_="'$_'";s/^''//;s/''$//}}continue {$ret .= "$_ "}chop$ret;return \@err,$ret}sub shell_quote {my ($rerr,$s)=_shell_quote_backend @_;if (@$rerr){my%seen;@$rerr=grep {!$seen{$_}++}@$rerr;my$s=join '',map {"shell_quote(): $_\n"}@$rerr;chomp$s;croak$s}return$s}sub shell_quote_best_effort {my ($rerr,$s)=_shell_quote_backend @_;return$s}sub shell_comment_quote {return '' unless @_;unless (@_==1){croak "Too many arguments to shell_comment_quote " ."(got " .@_ ." expected 1)"}local $_=shift;s/\n/\n#/g;return $_}1;
STRING_SHELLQUOTE

s/^  //mg for values %fatpacked;

my $class = 'FatPacked::'.(0+\%fatpacked);
no strict 'refs';
*{"${class}::files"} = sub { keys %{$_[0]} };

if ($] < 5.008) {
  *{"${class}::INC"} = sub {
    if (my $fat = $_[0]{$_[1]}) {
      my $pos = 0;
      my $last = length $fat;
      return (sub {
        return 0 if $pos == $last;
        my $next = (1 + index $fat, "\n", $pos) || $last;
        $_ .= substr $fat, $pos, $next - $pos;
        $pos = $next;
        return 1;
      });
    }
  };
}

else {
  *{"${class}::INC"} = sub {
    if (my $fat = $_[0]{$_[1]}) {
      open my $fh, '<', \$fat
        or die "FatPacker error loading $_[1] (could be a perl installation issue?)";
      return $fh;
    }
    return;
  };
}

unshift @INC, bless \%fatpacked, $class;
  } # END OF FATPACK CODE




package wp_tools;

use strict;
use warnings;

use App::WordPressTools;
our $VERSION = $App::WordPressTools::VERSION;

use sigtrap qw(die normal-signals);

use Digest::MD5 qw(md5_hex);
use Fcntl qw(:DEFAULT :flock);
use File::Find;
use File::Path;
use File::Slurper qw(read_text write_text);
use Getopt::Long qw(GetOptions);
use HTTP::Tiny;
use String::ShellQuote;


my $default = {
    backup_dir  => '',
    backup_file => '',
    components  => 'core,plugin,theme',
    force       => '',
    max_await   => 50,
    max_count   => 5,
    max_dproc   => 100,
    max_load    => 200,
    max_run     => 50,
    max_size    => 1024,    #MB
    min_space   => 25600,   #MB
    min_freemem => 1048576,
    path        => '',
    username    => '',
    wp_cli      => 'wp',
    skip_backup => undef,
};

my @backup_whitelist = qw(
.htaccess
favicon.ico
index.php
license.txt
readme.html
wp-activate.php
wp-admin
wp-blog-header.php
wp-comments-post.php
wp-config-sample.php
wp-config.php
wp-content
wp-cron.php
wp-includes
wp-links-opml.php
wp-load.php
wp-login.php
wp-mail.php
wp-settings.php
wp-signup.php
wp-trackback.php
xmlrpc.php
);

sub help {
    my $exit_status = shift;
    my $alert       = shift || '';
    print <<"END";
wp-tools makes backups of, upgrades, and restores backups of WordPress installations (files and databases)
usage:
wp-tools [command] [options]
e.g.
wp-tools backup  --path=WORDPRESSPATH --backupdir=BACKUPDIR ...
wp-tools upgrade --path=WORDPRESSPATH ...
wp-tools restore --backupfile=BACKUPFILE ...

    --help            show this help and exit
    --backupdir=str   path to store WordPress backups (required for backup)
    --backupfile=str  path to WordPress backup file (required for restore)
    --components=list comma-separated list of things to upgrade (default: $default->{components})
    --force           try hard to perform the command, disregarding limits if necessary
    --max-await=num   maximum time (ms) for IO requests on the system (default: $default->{max_await})
    --max-count=num   delete the oldest backups, keeping this many (default: $default->{max_count})
    --max-dproc=num   maximum number of defunct processes on the system (default: $default->{max_dproc})
    --max-load=num    maximum load average (default: $default->{max_load})
    --max-size=num    maximum size (in MB) of the installation (default: $default->{max_size})
    --max-run=num     maximum number of concurrent system-wide executions of this script (default: $default->{max_run})
    --min-freemem=num minimum amount of free memory on the system (default: $default->{min_freemem})
    --min-space=num   minimum amount of free space on the partition (default: $default->{min_space})
    --path=str        path to WordPress installation (required for backup, upgrade, optional for restore)
    --username=str    if root, drop privileges to specified user and chdir to user's home (required)
    --skip-backup     skips backup as part of an upgrade (not recommended, default: off)
    --wp-cli=str      command to execute when calling wp_cli (default: $default->{wp_cli})
END
    print "\n\n$alert\n" if $alert;
    exit(defined $exit_status ? $exit_status : 1);
}

if (grep { /^--version$/ } @ARGV) {
    print "WordPress Tools, version $VERSION\n";
    exit 0;
}

my $args = {%$default};
GetOptions(
    'backupdir=s'   => \$args->{'backup_dir'},
    'backupfile=s'  => \$args->{'backup_file'},
    'components=s'  => \$args->{'components'},
    'force'         => \$args->{'force'},
    'max-await=s'   => \$args->{'max_await'},
    'max-count=s'   => \$args->{'max_count'},
    'max-dproc=s'   => \$args->{'max_dproc'},
    'max-load=s'    => \$args->{'max_load'},
    'max-run=s'     => \$args->{'max_run'},
    'max-size=s'    => \$args->{'max_size'},
    'min-freemem=s' => \$args->{'min_freemem'},
    'min-space=s'   => \$args->{'min_space'},
    'path=s'        => \$args->{'path'},
    'username=s'    => \$args->{'username'},
    'wp-cli=s'      => \$args->{'wp_cli'},
    'skip-backup'   => \$args->{'skip_backup'},
    'help'          => sub { help(0) },
) or help;

my $command = lc($ARGV[0] || '');
if (   !$command
    || $command !~ /^(?:backup|restore|upgrade)$/
    || (!$args->{'backup_dir'}  && $command =~ /^(?:backup)$/)
    || (!$args->{'backup_dir'}  && $command =~ /^(?:upgrade)$/ && !$args->{'skip_backup'})
    || (!$args->{'path'}        && $command =~ /^(?:backup|upgrade)$/)
    || (!$args->{'backup_file'} && $command =~ /^(?:restore)$/)
    || (!$args->{'components'}  && $command =~ /^(?:upgrade)$/)
    || !$args->{'wp_cli'} ) {
    help(1, "Required parameter missing");
}

### check box load
if ($args->{max_load} && !$args->{force}) {
    open(my $fh, '<', '/proc/loadavg');
    my $loadfile = readline $fh;
    close $fh;
    my ($load) = $loadfile =~ /^(\S+)/;
    if (int($load) > $args->{max_load}) {
        die "Server load is too high ($load), please retry later.";
    }
}

### check box memory usage
if ($args->{min_freemem} && !$args->{force}) {
    my $mem = read_text(q{/proc/meminfo});
    my $free;
    for my $memcheck (qw(MemFree SwapFree Buffers Cached)) {
        ($free->{$memcheck}) = $mem =~ m/^$memcheck:*\s*(\d+)/gsm;
        $free->{$memcheck} ||= 0;
    }
    if (($free->{'Buffers'} + $free->{'Cached'} + $free->{'MemFree'}) < $args->{'min_freemem'}) {
        die "Insufficient available server memory (bcm), please retry later";
    }
    my $swapon = `swapon -s | wc -l`;
    chomp $swapon;
    $swapon--;
    if ($swapon && $free->{'SwapFree'} < $args->{'min_freemem'}) {
        die "Insufficient available server memory (s), please retry later";
    }
}

### check defunct process count
if ($args->{max_dproc} && !$args->{force}) {
    #my $dproc = `ps -o state | grep D | wc -l`;
    my $dproc = `awk '/procs_blocked/ {print \$2}' /proc/stat`;
    if ($dproc > $args->{'max_dproc'}) {
        die 'Process queue full, please try again later.';
    }
}

my ($uid, $gid, $home_dir);
### determine who we are or should be running as
if ($< == 0) {
    if (!$args->{'username'}) {
        help(1, "You cannot $command a WordPress installation as a root user");
    }
    ($uid, $gid, $home_dir) = (getpwnam $args->{'username'})[2, 3, 7];
}
else {
    my $username;
    ($username, $uid, $gid, $home_dir) = (getpwuid $<)[0, 2, 3, 7];
    $args->{'username'} = $username if !$args->{'username'};
}

### check space and average IO wait time of the home partition
if (my ($homeslash) = $home_dir =~ m{^(/home\d+)/} and !$args->{force}) {
    #get available space on /home for the user in question in POSIX standard
    my $df = `df -P $homeslash | tail -1`;
    my ($device,undef,undef,$available) = split(/\s+/, $df);
    #convert to MB
    my $mbavail  = $available / 1024;
    die "Not enough space available for backup ($mbavail MB)" if $mbavail < $args->{'min_space'};
    if ($args->{max_await} && $device !~ /^(?:rootfs|fakefs)/) {
        my $iostat = `iostat $device -dx 10 2 | tail -2`;
        chomp $iostat;
        my @iostat = split(/\s+/, $iostat);
        my $await = $iostat[9];
        if (!$await || $await !~ /^[0-9.]+$/) {
            warn "ignoring that await is not a number ($await)";
            $await = 0;
        }
        die "Average IO wait time ($await) is too high on $homeslash" if $args->{'max_await'} < $await;
    }
}

### drop permissions
if ($< == 0) {
    #dmother
    #added use English; equivalent statements for clarity
    #keeping punctuation variables for speed
    #$REAL_GROUP_ID = $EFFECTIVE_GROUP_ID = "$gid $gid";
    $( = $) = "$gid $gid";
    #$REAL_USER_ID = $EFFECTIVE_USER_ID = $uid;
    $< = $> = $uid;
    #cannot perform this action as root
    if ($< == 0) {
        die "Failed to relinquish privileges to user $args->{'username'}: $!";
    }
}
chdir($home_dir);

### prevent too many concurrent executions
our %pid_files;
sub create_pid_file {
    my $file = shift;
    return $pid_files{$file} if $pid_files{$file};
    sysopen(my $fh, $file, O_RDWR|O_CREAT) or die "Open pid file failed: $!";
    flock($fh, LOCK_EX|LOCK_NB) or die "Locking pid file ($file) failed: $!";
    chmod(0666, $file);     # explicitly ignore chmod errors since we may not be the owner
    print $fh "$$\n";
    return $pid_files{$file} = $fh;
}
sub unlink_pid_file {
    my $file = shift;
    my $fh   = $pid_files{$file} or return;
    close($fh);
    unlink($file);      # explicitly ignore unlink errors since we may not be the owner
}
for my $i (1..$args->{max_run}) {
    my $num  = sprintf('%04d', $i);
    my $file = "/tmp/wp_backup-${num}.pid";
    last if eval { create_pid_file($file) };
}
if (!keys %pid_files && !$args->{force}) {
    die 'Too many concurrent executions; try again later.';
}
sub _lock_path {
    my $path = shift;
    $path =~ s!/*$!!;
    my $hash = md5_hex($path);
    create_pid_file(".wp_backup-${hash}.pid");
    return $hash;
}
END {
    unlink_pid_file($_) for (keys %pid_files);
}

my $nice_path    = $args->{path} || '';
$nice_path       =~ s/^\///;
my @parts        = split '/', $nice_path;
my $wpdir        = $parts[-1] || '';
my $parent       = $nice_path;
$parent          =~ s/\Q$wpdir\E\/?//;
my $parentq      = shell_quote($parent);
my $wpdirq       = shell_quote($wpdir);
my $pathq        = shell_quote($nice_path);
my ($wp_cli_path, $version, $canonversion, $plus3713);
my $canon3713    = _canon_ver('3.7.13');
our $maintenance;
our $mode;
our $definition_check_string = '/*WP-CLI_DEFINITION_CHECK*/';
if ($command =~ /^(backup|upgrade)$/) {
    $wp_cli_path  = "$args->{'wp_cli'} --path=$pathq";
    $version      = _run_wpcli($nice_path, 'core version');
    chomp $version;
    $canonversion = _canon_ver($version);
    $plus3713     = !!($canonversion ge $canon3713);
}

if (my $method = __PACKAGE__->can($command)) {
    my $return = eval{$method->()};
    if ($@) {
        print "Unable to $command: $@";
        exit 1;
    }
    elsif ($return && ref $return) {
        print "$return->{'message'}\n" || "Successfully completed $command operation.\n";
        exit($return->{'success'} ? 0 : 1);
    }
    exit 1;
}

sub backup {
    my $time            = time;
    my $hash            = _lock_path($nice_path);

    my $backup_file     = "wp_backup${time}.tar.gz";
    our $db_file        = "wp_backup${hash}.sql";
    our $manifest_file  = "wp_backup${hash}.MANIFEST";
    our $defaults_file  = "wp_backup${hash}.temporary.my.cnf";

    my $skips = {};

    ### check size of WordPress installation
    if ($args->{max_size} && !$args->{force}) {
        # find directories that may be skipped
        my $skippable = {};
        my $wp_content_path = shell_quote("$args->{'path'}/wp-content");
        my $dums = eval{`du -ms $wp_content_path/*`};
        my $wp_content_size;
        for my $entry (split(/[\r\n]+/, $dums)) {
            my ($size, $path) = $entry =~ m/^(\d+).*wp-content\/(.*)$/;
            $wp_content_size->{$path} = $size;
        }
        eval {
            opendir (my $dh, $wp_content_path) || die;
            while (my $path = readdir $dh) {
                next if $path eq '.' || $path eq '..';
                if ($path =~ /(?:backup|upload)/i) {
                    $skippable->{$path} = $wp_content_size->{$path};
                }
                if ($wp_content_size->{$path} && $wp_content_size->{$path} > 200 && $path !~ /^(?:themes|plugins|mu-plugins|translations|languages)$/) {
                    $skippable->{$path} = $wp_content_size->{$path};
                }
            }
        };

        my @paths = map { -e "$nice_path/$_" ? shell_quote("$nice_path/$_") : () } @backup_whitelist;
        my $paths = join(' ', @paths);
        my $size = eval { `du -msc $paths` } || '';
        $size =~ s/.*?(\d+)\s+total.*/$1/s;
        if (!$size || $size !~ /^\d+$/) {
            die 'Cannot determine size of WordPress installation';
        }
        if ($args->{max_size} < $size) {
            # try to reduce content that is included in the backup
            my $backupsize = $size;
            for my $type (sort { $skippable->{$b} <=> $skippable->{$a} } keys %$skippable) {
                my $skip_path   = "$args->{'path'}/wp-content/$type";
                my $skip_pathq  = shell_quote($skip_path);
                next if !-d $skip_path;
                $skips->{$type} = $skippable->{$type} || eval { `du -ms $skip_pathq` } || 0;
                $skips->{$type} =~ s/^(\d+).*/$1/s;
                $backupsize -= $skips->{$type};
                last if $backupsize <= $args->{max_size};
            }
            if ($args->{max_size} < $backupsize) {
                die "Cannot backup this WordPress installation because it is too large ($size/$backupsize)";
            }
        }
    }

    ### backup database
    my $result = '';
    my $dump_command = '';

    # we cannot check the database without wp-config.php (credential storage location)
    if (!-f "$nice_path/wp-config.php") {
        $args->{'__skip_database'} = 1;
    }
    else {
        #acceptable failure states for databaseless accounts
        my $no_db_regex = qr/(?:Access denied for user|Unknown MySQL server host|Unknown database.*when selecting the database|is marked as crashed and last \(automatic\?\) repair failed when using LOCK TABLES|Got error: 130: Incorrect file format|Got error: 1146: Table.*doesn't exist when using LOCK TABLES|Got error: 1033: Incorrect information in file:|Got error: 1034: Incorrect key file for table|'Got error 28 from storage engine' when trying to dump tablespaces|Couldn't execute 'show fields from|references invalid table\(s\) or column\(s\) or function\(s\) or definer\/invoker of view lack rights to use them when using LOCK TABLE|Got error: 1017: Can't find file:)/;
        if ($plus3713) {
            $dump_command = "db export $db_file --add-drop-table 2>&1";
            $result = _run_wpcli($nice_path, $dump_command);
        }
        if ($result =~ $no_db_regex) {
            $args->{'__skip_database'} = 1;
        }
        elsif ($result !~ /^Success/) {
            # wp-cli backup can fail for wp <3.7.13, so try mysqldump instead
            my $wp_configq = shell_quote("$args->{'path'}/wp-config.php");
            my $username = `grep DB_USER     <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
            my $password = `grep DB_PASSWORD <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
            my $database = `grep DB_NAME     <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
            #disallow starting whitespace
            $username =~ s/^[\r\n]+//;
            $password =~ s/^[\r\n]+//;
            $database =~ s/^[\r\n]+//;
            chomp $username;
            chomp $password;
            chomp $database;
            if ($username =~ /[\r\n]/ || $password =~ /[\r\n]/ || $database =~ /[\r\n]/) {
                die "Multiple credentials found in $args->{'path'}/wp-config.php.  Cannot determine which to use.  Backup operation halted.";
            }
            open (my $fh, '>', $defaults_file) or die "Cannot write to $defaults_file: $!";
            close $fh;
            chmod(0600, $defaults_file) or die "Cannot chmod $defaults_file: $!";
            write_text($defaults_file,"[client]\nuser=$username\npassword=$password");
            my $databaseq = shell_quote($database);
            $dump_command = "mysqldump --defaults-file=$defaults_file $databaseq 2>&1 >$db_file";
            my $result = `$dump_command`;
            #acceptable failure states for databaseless accounts
            if ($result =~ $no_db_regex) {
                $args->{'__skip_database'} = 1;
                $db_file = '';
            }
            elsif ($?) {
                die "mysqldump command ($dump_command) failed (exit: $?): $result";
            }
        }
        if (!$args->{'__skip_database'}) {
            if (!-f $db_file || -s $db_file < 1024) {
                die "Aborting because there doesn't seem to be any data to back up (command: $dump_command)";
            }
            open my $db_test, '<', $db_file;
            my $first_line = <$db_test>;
            close $db_test;
            if ($first_line =~ /Usage: mysqldump/) {
                die "Database dump looks like it failed because it contains usage (command: $dump_command)";
            }
        }
    }

    ### backup filesystem
    my $backup_filename = "$args->{backup_dir}/$backup_file";
    mkpath($args->{backup_dir}) if !-d $args->{backup_dir};
    my $exclusions = '';
    for my $type (keys %$skips) {
        if (!$skips->{$type}) {
            delete $skips->{$type};
            next;
        }
        my $spath = "$wpdir/wp-content/$type";
        $spath = "./$spath" if $spath =~ /^-/;
        my $skip_path = shell_quote($spath);
        $exclusions .= " --exclude $skip_path";
    }
    my $inclusions = '';
    for my $file (@backup_whitelist) {
        next if !-e "$args->{'path'}/$file";
        my $apath = "$wpdir/$file";
        $apath = "./$apath" if $apath =~ /^-/;
        my $add_path = shell_quote($apath);
        $inclusions .= " $add_path";
    }
    open(my $fh, '>', $manifest_file) or die "Cannot write to $manifest_file: $!";
    print $fh "version:1\n";
    print $fh "path:$nice_path\n";
    print $fh "time:$time\n";
    print $fh "nodb:1\n" if $args->{'__skip_database'};
    if (scalar keys %$skips) {
        print $fh "skipped:".join(',', keys %$skips)."\n";
    }
    close $fh;
    my $transform = "--transform='s/^$manifest_file\$/wp_backup.MANIFEST/' --transform='s/^$db_file\$/wp_backup${time}.sql/'";
    my $cd = $parent ? "-C $parentq" : '';
    my $backup = `tar -czf $backup_filename $transform $manifest_file $db_file $cd $exclusions $inclusions`;
    if (!-e $backup_filename) {
        die 'Failed to create backup file';
    }

    ### delete old backups
    if ($args->{max_count} && $args->{max_count} =~ /^\d+$/) {
        my @files;
        File::Find::find({
            no_chdir    => 1,
            wanted      => sub {
                push @files, $_ if -f && m{/wp_backup\d+\.tar\.gz$};
            },
        }, $args->{'backup_dir'});

        my @backups;
        for my $file (@files) {
            my ($time) = $file =~ m{wp_backup(\d+)\.tar\.gz$};
            push @backups, {
                file      => $file,
                timestamp => $time,
            };
        }
        my $count = 0;
        for my $backup (sort { $b->{timestamp} <=> $a->{timestamp} } @backups) {
            $count += 1;
            if ($args->{'max_count'} < $count) {
                unlink $backup->{file};
            }
        }
    }

    ### cleanup
    END {
        unlink($db_file)        if $db_file && -e $db_file;
        unlink($manifest_file)  if $manifest_file && -e $manifest_file;
        unlink($defaults_file)  if $defaults_file && -e $defaults_file;
    }

    return {
        success     => 1,
        path        => $args->{'path'},
        file        => $backup_file,
        backup_file => "$args->{'backup_dir'}/$backup_file",
        message     => "Successfully backed up WordPress from $args->{'path'} to $backup_file",
    };
}

sub restore {
    if (!-e $args->{backup_file}) {
        die "Backup file $args->{backup_file} not found";
    }

    my $backup_fileq = shell_quote($args->{'backup_file'});
    my $manifest = eval { `tar -xOzf $backup_fileq --occurrence=1 wp_backup.MANIFEST 2>/dev/null` } || '';
    my %manifest;
    if (!$? && $manifest) {
        %manifest = map { /^(\w+?):(.*)$/ ? ($1 => $2) : () } split(/\n/, $manifest);
    }

    my $hash        = _lock_path($nice_path);
    my ($time)      = $manifest{time} ? ($manifest{time}) : $args->{backup_file} =~ /wp_backup(\d+)\.tar\.gz$/;
    # time is needed to know the name of the database file in the tarball.
    $time or die 'Cannot determine time of backup';
    our $db_file        = "wp_backup${hash}.sql";
    our $defaults_file  = "wp_backup${hash}.temporary.my.cnf";
    my $path        = $args->{path} || $manifest{path} or die 'Cannot determine path to restore to';
    $nice_path      = $manifest{path} || $path;
    $nice_path      =~ s/^\///;
    @parts          = split '/', $nice_path;
    $wpdir          = $parts[-1];

    my $wpdirq      = shell_quote($wpdir);
    my $pathq       = shell_quote($nice_path);

    our $saved_path = $path;
    $saved_path =~ s!/+$!!;
    $saved_path = "${saved_path}.restore";

    if (-d $path) {
        my $saved_pathq = shell_quote($saved_path);
        my $err_out = `cp -al $pathq $saved_pathq 2>&1`;
        if ($?) {
            die "Could not copy $path to $saved_path: $err_out";
        }
    }

    eval {
        my $del  = _find_sed_delimiter($wpdir, $path);
        my $bre  = _bre_quote($wpdir);
        my $repl = _bre_quote($path, '\&');
        if (!$del) {
            die 'No available delimiter found to use with tar -x --transform';
        }
        my $transform = shell_quote("--transform=s${del}^$bre${del}$repl${del}");
        my $restore_cmd = "tar -xzf $backup_fileq --recursive-unlink $transform $wpdirq 2>&1";
        my $restore = `$restore_cmd`;
        if ($?) {
            die "File restore command ($restore_cmd) exited non-zero ($?): $restore";
        }
        if (!-d $path) {
            die "File restore command ($restore_cmd) failed to actually restore files";
        }

        if (!$manifest{'nodb'}) {
            my $transform = "--transform='s/^wp_backup${time}\\.sql\$/$db_file/'";
            my $db_restore = `tar -xzf $backup_fileq $transform wp_backup${time}.sql 2>&1`;
            if ($? || !-f $db_file) {
                die "Cannot extract database restore file ($db_file): $db_restore";
            }
            $wp_cli_path  = "$args->{'wp_cli'} --path=".shell_quote($path);
            $version      = _run_wpcli($path, 'core version');
            chomp $version;
            $canonversion = _canon_ver($version);
            $plus3713     = !!($canonversion ge $canon3713);
            if ($plus3713) {
                my $dbfile = _run_wpcli($path, "db import $db_file --skip-plugins --skip-themes");
            }
            if (!$plus3713 || $?) {
                my $wp_configq = shell_quote("$path/wp-config.php");
                if (!-f "$path/wp-config.php") {
                    die "Missing wp-config.php";
                }
                my $username = `grep DB_USER      <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
                my $password = `grep DB_PASSWORD  <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
                my $database = `grep DB_NAME      <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
                #disallow starting whitespace
                $username =~ s/^[\r\n]+//;
                $password =~ s/^[\r\n]+//;
                $database =~ s/^[\r\n]+//;
                chomp $username;
                chomp $password;
                chomp $database;
                if ($username =~ /[\r\n]/ || $password =~ /[\r\n]/ || $database =~ /[\r\n]/) {
                    die "Multiple credentials found in $args->{'path'}/wp-config.php.  Cannot determine which to use.  Restoration operation halted.";
                }
                open (my $fh, '>', $defaults_file) or die "Cannot write to $defaults_file: $!";
                close $fh;
                chmod(0600, $defaults_file) or die "Cannot chmod $defaults_file: $!";
                write_text($defaults_file,"[client]\nuser=$username\npassword=$password");
                my $databaseq = shell_quote($database);
                `mysql --defaults-file=$defaults_file $databaseq <$db_file`;
                if ($?) {
                    die "Failed to restore database";
                }
            }
        }

        # if we skipped large directories in the backup procedure
        # we must copy them from the installation we are replacing
        my @skipped = split(/,/, $manifest{'skipped'} || '');
        for my $dir (@skipped) {
            my $src = "${saved_path}/wp-content/$dir";
            my $dst = "${path}/wp-content/$dir";
            if (-d $src) {
                rmtree($dst) if -e $dst;
                my $srcq = shell_quote($src);
                my $dstq = shell_quote($dst);
                my $err_out = `cp -al $srcq $dstq 2>&1`;
                if ($?) {
                    die "Could not copy $path to $saved_path: $err_out";
                }
            }
            else {
                # TODO - should this condition be fatal?
                warn "Expected to restore using $dir in installation being replaced, but it is missing";
            }
        }
    };
    if ($@) {
        my $err = $@;
        if (-d $saved_path) {
            my $defunct_path = $path;
            $defunct_path =~ s!/+$!!;
            $defunct_path .= ".defunct_" . time;
            if (rename($path, $defunct_path)) {
                if (!rename($saved_path, $path)) {
                    # this is the sad case
                    $err .= "; also could not move $saved_path back to $path: $!";
                    undef $saved_path;  # do not wipe out if we couldn't fully fix it
                    rename($defunct_path, $path);
                }

                if (-d $defunct_path) {
                    rmtree($defunct_path);
                }
            }
        }
        die $err;
    }

    ### cleanup
    END {
        unlink($db_file)        if $db_file && -e $db_file;
        unlink($defaults_file)  if $defaults_file && -e $defaults_file;
        rmtree($saved_path)     if $saved_path && -d $saved_path;
    }

    return {
        success => 1,
        path    => $path,
        file    => $args->{'backup_file'},
        message => "Successfully restored WordPress from $args->{'backup_file'} to $path",
        ($args->{'failed'} ? (update_failure => $args->{'failed'}) : ()),
    };
}

sub _canon_ver {(my $n=shift)=~s/(\d+)/sprintf "%06d", $1/eg; $n =~ tr/-:_/.../; return $n}

sub upgrade {
    my $hash            = _lock_path($nice_path);
    our $defaults_file  = "wp_backup${hash}.temporary.my.cnf";

    my %components = map { /^(core|plugin|theme)s?$/i ? (lc($1) => 1) : () } split(/,/, $args->{'components'});

    if ($plus3713) {
        ### check for possible updates
        ### this check only works 3.7.13+, however 3.7.12- are guaranteed to have updates
        my $core_check = _run_wpcli($nice_path, 'core check-update --skip-plugins --skip-themes 2>&1');
        if ($components{'core'} && (!$core_check || $core_check =~ /Success: WordPress is at the latest version./) && !$?) {
            delete $components{'core'};
        }
        for my $type (grep { $components{$_} } qw(plugin theme)) {
            my $check = _run_wpcli($nice_path, "$type update --all --dry-run");
            if ($check =~ /No $type updates available/) {
                delete $components{$type};
            }
        }
    }
    if ($args->{'__skip_database'}) {
        for my $type (qw(theme plugin)) {
            delete $components{$type} if $components{$type};
        }
    }
    ### exit if no updates available
    if (!keys %components) {
        print "No updates available.\n";
        exit;
    }

    ### if not explicitly refused, make a backup first
    my $backup = !$args->{'skip_backup'} ? backup() : undef;
    die "Unable to make backup." if !$args->{'skip_backup'} && (!$backup || !ref $backup || !$backup->{'success'});
    if ($backup && ref $backup && $backup->{'success'}) {
        $args->{'backup_file'} = $backup->{'backup_file'};
    }
    if (!$args->{'skip_backup'} && (length($args->{'backup_file'}) == 0 || !-e $args->{'backup_file'} || !-s $args->{'backup_file'})) {
        die "Unable to read backup file - upgrade stopped.";
    }

    #find all non-executable directories and make the executable (for listing)
    my $fix_directories = `find $pathq -type d ! -perm /u+x -exec chmod u+x {} \\; ;`;
    #find all non-writable files and make them user writable
    my $set_permissions = `find $pathq ! -perm /u+w -exec chmod u+w {} \\; ;`;

    #if a backup is made, disable maintenance mode temporarily
    if (-e '.maintenance') {
        $maintenance = '.not.maintenance';
        rename('.maintenance',$maintenance);
    }

    my $current_status;
    my $http = HTTP::Tiny->new(timeout => 30);
    if ($plus3713) {
        ### default wp-cli status check
        $current_status->{'wpcli_std'} = _run_wpcli($nice_path, q{eval 'echo "ok";'});
        chomp $current_status->{'wpcli_std'} if $current_status->{'wpcli_std'};
        ### npt "safe mode" status check
        $current_status->{'wpcli_npt'} = _run_wpcli($nice_path, q{--skip-plugins --skip-themes eval 'echo "ok";'});
        chomp $current_status->{'wpcli_npt'} if $current_status->{'wpcli_npt'};
        ### get url and current default page size/status code
        $current_status->{'siteurl'}  = _run_wpcli($nice_path, q{option get siteurl});;
        $current_status->{'adminurl'} = "$current_status->{'siteurl'}/wp-admin";
        my $resp = $http->head($current_status->{'siteurl'});
        $current_status->{'code'} = $resp->{'status'};
        $current_status->{'size'} = $resp->{'headers'}{'content-length'} || 1;
        my $aresp = $http->head($current_status->{'adminurl'});
        $current_status->{'admincode'} = $aresp->{'status'};
        $current_status->{'adminsize'} = $aresp->{'headers'}{'content-length'} || 1;
    }
    elsif (-f "$args->{'path'}/wp-config.php") {
        ### get url and current default page size/status code
        my $wp_configq = shell_quote("$args->{'path'}/wp-config.php");
        my $username = `grep DB_USER      <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
        my $password = `grep DB_PASSWORD  <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
        my $database = `grep DB_NAME      <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 4`;
        my $prefix   = `grep table_prefix <$wp_configq | grep -v '$definition_check_string' | cut -d \\' -f 2` || 'wp_';
        $prefix      =~ s/[^\w_-]//g;
        #disallow starting whitespace
        $username =~ s/^[\r\n]+//;
        $password =~ s/^[\r\n]+//;
        $database =~ s/^[\r\n]+//;
        chomp $username;
        chomp $password;
        chomp $database;
        if ($username =~ /[\r\n]/ || $password =~ /[\r\n]/ || $database =~ /[\r\n]/) {
            die "Multiple credentials found in $args->{'path'}/wp-config.php.  Cannot determine which to use.  Upgrade operation halted.";
        }
        if ($prefix =~ /[\r\n]/) {
            die "Multiple database prefixes found in $args->{'path'}/wp-config.php.  Cannot determine which to use.  Upgrade operation halted.";
        }
        open (my $fh, '>', $defaults_file) or die "Cannot write to $defaults_file: $!";
        close $fh;
        chmod(0600, $defaults_file) or die "Cannot chmod $defaults_file: $!";
        write_text($defaults_file,"[client]\nuser=$username\npassword=$password");
        my $table = "${prefix}options";
        my $databaseq = shell_quote($database);
        my $siteurl_sql = qq{mysql -N -B -e --defaults-file=$defaults_file $databaseq "SELECT option_value FROM $table WHERE option_name = 'siteurl'"};
        $current_status->{'siteurl'} = `$siteurl_sql`;
        $current_status->{'adminurl'} = "$current_status->{'siteurl'}/wp-admin";
        my $resp = $http->head($current_status->{'siteurl'});
        $current_status->{'code'} = $resp->{'status'};
        $current_status->{'size'} = $resp->{'headers'}{'content-length'} || 1;
        my $aresp = $http->head($current_status->{'adminurl'});
        $current_status->{'admincode'} = $aresp->{'status'};
        $current_status->{'adminsize'} = $aresp->{'headers'}{'content-length'} || 1;
    }

    eval {
        if ($components{'core'}) {
            my $update = _run_wpcli($nice_path, ($args->{'force'} || !$plus3713) ? "core download --force 2>&1" : "core update 2>&1");
            #try forcing errors
            $update = _run_wpcli($nice_path, q{core download --force 2>&1}) if $?;
            die "Upgrading WordPress core files exited with $? ($update)" if $?;
            if (!$args->{'__skip_database'}) {
                my $updatedb = _run_wpcli($nice_path, q{core update-db 2>&1});
                #try harder
                if ($?) {
                    $updatedb = _run_wpcli($nice_path, q{core update-db  --skip-plugins --skip-themes 2>&1});
                }
                #allowable database failures
                if ($updatedb !~ /(?:The site you have requested is not installed.)/) {
                    die "Upgrading WordPress core database exited with $? ($updatedb)" if $?;
                }
            }
        }
        my $pt_ok = qr/(?:Warning: Update package not available.|Error establishing a database connection)/;
        if ($components{'plugin'}) {
            my $plugins  = _run_wpcli($nice_path, q{plugin update --all 2>&1});
            if ($? && $plugins !~ /$pt_ok/gsm) {
                die "Upgrading plugins exited with $? ($plugins)";
            }
        }
        if ($components{'theme'}) {
            my $themes   = _run_wpcli($nice_path, q{theme update --all 2>&1});
            if ($? && $themes !~ /$pt_ok/gsm) {
                die "Upgrading themes exited with $? ($themes)" if $?;
            }
        }
    };
    if ($@) {
        $args->{'failed'} = $@;
    }
    if (!$args->{'failed'} && $plus3713) {
        ### default wp-cli status check
        if ($current_status->{'wpcli_std'} eq 'ok') {
            my $test = _run_wpcli($nice_path, q{eval 'echo "ok";'});
            chomp $test;
            $args->{'failed'} = 'Failed standard WordPress check after update' if $test ne 'ok';
        }
        if (!$args->{'failed'} && $current_status->{'wpcli_npt'} eq 'ok') {
            my $test = _run_wpcli($nice_path, q{--skip-plugins --skip-themes eval 'echo "ok";'});
            chomp $test;
            $args->{'failed'} = 'Failed safe mode WordPress check after update' if $test ne 'ok';
        }
    }
    if (!$args->{'failed'} && $current_status->{'siteurl'}) {
        ### get current default page size and status
        my $resp       = $http->head($current_status->{'siteurl'});
        my $after_size = $resp->{'headers'}{'content-length'} || 1;
        my $average    = ($current_status->{'size'} + $after_size) / 2;
        my $div        = $current_status->{'size'}/$after_size;
        if ($div > 1.5 || $div < .5) {
            $args->{'failed'} = 'Site download size changed by more than 50% after update (assuming failure).';
        }
        my $code = $resp->{'status'};
        if (!$args->{'failed'} && $code ne $current_status->{'code'} && $code ne '200' && $current_status->{'code'} !~ /^(?:4|5)/) {
            $args->{'failed'} = "Site download status changed from $current_status->{'code'} to $code (assuming failure)";
        }
    }
    if (!$args->{'failed'} && $current_status->{'adminurl'}) {
        ### get current default page size and status
        my $resp       = $http->head($current_status->{'adminurl'});
        my $after_size = $resp->{'headers'}{'content-length'} || 1;
        my $average    = ($current_status->{'adminsize'} + $after_size) / 2;
        my $div        = $current_status->{'adminsize'}/$after_size;
        if ($div > 1.5 || $div < .5) {
            $args->{'failed'} = 'Site admin download size changed by more than 50% after update (assuming failure).';
        }
        my $code = $resp->{'status'};
        if (!$args->{'failed'} && $code ne $current_status->{'admincode'} && $code ne '200' && $current_status->{'admincode'} !~ /^(?:4|5)/) {
            $args->{'failed'} = "Site admin download status changed from $current_status->{'admincode'} to $code (assuming failure)";
        }
    }

    ### cleanup
    END {
        unlink($defaults_file) if $defaults_file && -e $defaults_file;
        rename($maintenance,'.maintenance') if $maintenance;
    }

    #fail case vvv
    if ($args->{'failed'}) {
        print "Upgrade failure detected:$args->{'failed'}. Restoring from backup $args->{'backup_file'}...\n";
        my $result = restore();
        $result->{'success'} = 0;
        return $result;
    }
    else {
        my $upgraded = join(', ', map { $_ eq 'core' ? 'WordPress' : "${_}s" } keys %components);
        return {
            success => 1,
            path    => $args->{'path'},
            message => "Successfully upgraded $upgraded from $args->{'path'}",
        };
    }
}

sub _bre_quote {
    my $str = shift;
    my $bre = shift || '$.*[\]^';
    $str =~ s/([\Q$bre\E])/\\$1/g;
    $str =~ s/\n/\\n/g;
    return $str;
}

# to work around the fact that `tar --transform' can't correctly escape the
# delimiter of a sed substitution expression in the replacement text, this
# subroutine finds a delimiter that can be used safely without escaping
sub _find_sed_delimiter {
    my $str = join('', @_);
    my $bre = '$.*[\]^';
    for my $n (1..255) {
        my $del = pack('C', $n);
        return $del if $str !~ /\Q$del\E/ && $del !~ /[\Q$bre\E]/;
    }
}

sub _run_wpcli {
    my $path    = shift;
    my $command = shift;

    _fix_wp_config($path);
    my $ret = `$wp_cli_path $command`;
    my $status = $?;
    _restore_wp_config();

    $? = $status;
    return $ret;
}

### fix wp-config.php to workaround wpcli bug
#   See https://github.com/wp-cli/wp-cli/issues/1631
sub _fix_wp_config {
    my $path = shift or die 'Path argument required';

    our $config_file    = "$path/wp-config.php";
    our $config_backup  = "$config_file.backup";

    my $config_fileq    = shell_quote($config_file);
    my $config_backupq  = shell_quote($config_backup);

    return if !-e $config_file;

    # make sure we are not generating from an auto-generated config
    my $config_content = `cat $config_fileq`;
    if ($config_content =~ m!WARNING: This config is auto-generated from .* for wpcli compatibility!) {
        return;
        #die "Refusing to generate wpcli-compatible wp-config.php because we already did";
    }

    # copy config to a backup location
    my $err_out = `cp $config_fileq $config_backupq 2>&1`;
    if ($?) {
        die "Could not copy $config_file to $config_backup: $err_out";
    }

    # generate the new config
    open(my $in,  '<', $config_backup) or die "Failed to open (cbf) $config_backup: $!";
    #temporarily set permissions to rw?
    $mode = (stat($config_file))[2] & 0777;
    my $modestr = sprintf qq{%04o}, $mode;
    if ($modestr !~ /^.[67]/) {
        chmod($mode | 0600, $config_file);
    }
    else {
        undef $mode;
    }
    open(my $out, '>', $config_file) or die "Failed to open (cfw) $config_file $!";
    print $out "<?php\n";
    print $out "/* WARNING: This config is auto-generated from $config_backup for wpcli compatibility! */\n";
    while (my $line = <$in>) {
        if ($line =~ /(?:define\((.+?),.+\)\s*;|\$\w+\s*=\s*['"].*['"]\s*;)/) {
            $line = "if (!defined($1)) {$definition_check_string\n$line\n}$definition_check_string\n" if $1;
            print $out $line;
        }
    }
    print $out "require_once(ABSPATH . 'wp-settings.php');\n";
    close($in);
    close($out);

    END {
        _restore_wp_config();
    }
}

sub _restore_wp_config {
    our $config_file;
    our $config_backup;

    # restore original wp-config.php
    if ($config_backup && -e $config_backup) {
        unlink($config_file);
        rename($config_backup, $config_file);
    }
    chmod($mode, $config_file) if $mode;
}

